{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§  Extract spatial \"hotspots\" of activity from voltage imaging recording\n",
    "### Steps\n",
    "\n",
    "1) Import stuff \n",
    "2) Set data with labelled blobs of significant activity \n",
    "3) Create class for analysis and get normalised + temporally summed 2D activity heatmaps\n",
    "4) Get distance between each heatmap, and threshold for significance using spatial shuffling\n",
    "5) Cluster heatmaps based on distance, get similarity matrix \n",
    "6) Perform background correction (optional): remove overall weakly correlated heatmaps which are more likely noise\n",
    "7) Get heatmaps & similarity matrices for each level of the linkage hierarchy. Plot matrices w clusters highlighted.\n",
    "8) Search through the tree and find spatially significant hotspots, then plot/save\n",
    "\n",
    "To do:\n",
    "1) Check significance calculation between clusters\n",
    "2) Improve speed of tree-search algorithm\n",
    "4) Memory map results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-07 20:31:25,972\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "<frozen importlib._bootstrap_external>:1181: FutureWarning: The cuda.cudart module is deprecated and will be removed in a future release, please switch to use the cuda.bindings.runtime module instead.\n",
      "<frozen importlib._bootstrap_external>:1181: FutureWarning: The cuda.cuda module is deprecated and will be removed in a future release, please switch to use the cuda.bindings.driver module instead.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, os, sys, importlib, glob, matplotlib.pyplot as plt, seaborn as sns, pickle as pkl, itertools\n",
    "from scripts import dfFunc as f, vFunc as vF, pltFunc as pF, analyse, synFunc as sF, synAnalysis as synAn\n",
    "sns.set_style('white')\n",
    "#sys.path.append('../NetAnalysis/Ensembles/scripts')\n",
    "#import eFunctions as eF, ePltFunc as eP\n",
    "def rel(): importlib.reload(f),importlib.reload(vF),importlib.reload(pF),importlib.reload(synAn), importlib.reload(analyse), importlib.reload(sF) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - 3) Specify data and create class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data with blobs of significant activity from getActivity.ipynb. Get heatmaps of activity summed over temporal frames: ie, each heatmap is of length N x M pixels, and each value corresponds to the (normalised) temporally summed intensity over the blob of activity. The activity is normalised because if 2 heatmaps have the same intensity distribution, apart from the scaled magnitude, they probably come from the same synaptic input! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting continuous activity episodes + labels... 463  activity episodes\n",
      "getting normalised activity episodes... (using gpu for temporal heatmap)\n"
     ]
    }
   ],
   "source": [
    "Data = 'data/cntData_test.pkl'      # Path to data with labelled \"blobs\" of activity (getActivity.ipynb)\n",
    "synClust = synAn.synClust(Data)         # Analysis class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Get measure of distance between each heatmap, and threshold distance for significance with spatial shuffling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find a distance measure between all heatmaps to use for clustering. Set a threshold for significance by randomly spatially shuffling every heatmap N times, recalculating distance between every heatmap pair, and using a cutoff based on these distribution of values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting distance\n",
      "getting random heatmap locations..getting random distances..\n"
     ]
    }
   ],
   "source": [
    "rel()\n",
    "PERCENTILE = 90                 # Percentile threshold for significance (input 100 - this bc it's distance...)\n",
    "Runs = 100                      # Number of shuffling runs\n",
    "batchSize = (10, 10)            # Batch sizes for GPU: reduce if running out of memory....\n",
    "METRIC = 'correlation'          # Metric for calculating similarity between heatmaps\n",
    "\n",
    "synClust.getDistance(Runs, batchSize, percentile = 100 - PERCENTILE, \\\n",
    "                     shufflePlot = False, Metric = METRIC) # 3000 episodes = 140 seconds for 1k runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-6) Cluster heatmaps based on distance and get similarity matrix. Perform a final background correction (optional?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform clustering on the heatmap distance matrix, and create a matrix of cluster hierarchies, and a similarity matrix.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting matrix of cluster hierarchies\n"
     ]
    }
   ],
   "source": [
    "synClust.getClusters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Background correction (optional). The rationale for this is because heatmaps that are overall weakly correlated are probably more likely to be due to background noise. This finds the distribution of mean correlations of all heatmaps that are restricted to \"non-cell\" locations. Any heatmaps that have a mean correlation less than a threshold, based on this distribution, are removed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uncorrected activity matrix shape:  (1435, 463)\n",
      "getting distance\n",
      "corrected activity matrix shape:  (1435, 162)\n"
     ]
    }
   ],
   "source": [
    "CORRECT = True                              # Perform background correction?\n",
    "BG_PERCENTILE = 90                          # %ile for cutoff\n",
    "SPLITS = 1                                  # For GPU: increase if memory issues....\n",
    "\n",
    "print('uncorrected activity matrix shape: ', synClust.actM.shape)\n",
    "synClust.bgCorrection(Percentile = BG_PERCENTILE, Correct = CORRECT, SPLITS = SPLITS) # change SPLIT for GPU memory use\n",
    "print('corrected activity matrix shape: ', synClust.actM.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-calculate clustering etc if background correction is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting matrix of cluster hierarchies\n"
     ]
    }
   ],
   "source": [
    "synClust.getClusters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Get heatmaps within each cluster for each level of the linkage hierarchy. Plot ordered similarity matrices. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot matrices corresponding to different levels of the clustering hierarchy (starting with a single cluster), with each cluster ordered by within-cluster distance. Get heatmaps corresponding to each cluster at hierarchy level.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x71bcff9076d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nHierarchies = 20               # Choose arbitrary upper number of cluster hierarchies (just need enough to cover most activity...)\n",
    "\n",
    "plt.ioff()\n",
    "rows = np.linspace(-(nHierarchies + 1), -1, nHierarchies + 1).astype(int)\n",
    "synClust.plotSortSim(rows, sHigh = False, save = False, Par = False)\n",
    "plt.close('all')\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a cluster hierarchy level that \"covers\" a certain proportion of the total activity (eg, 90%). This level will then be used to search for all significantly separated clusters....   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster level and percentage for > 90 perc cell coverage is (15, 0.9729404)\n",
      "not enough hierarchies to cover 95.0 percent of total activity!\n"
     ]
    }
   ],
   "source": [
    "PERC_COVER = 0.95\n",
    "\n",
    "try:\n",
    "      print('cluster level and percentage for > 90 perc cell coverage is',\\\n",
    "            [(K,V) for K, V in synClust.activityCover['cell'].items() if V > PERC_COVER][-1])\n",
    "except:\n",
    "      print(\"not enough hierarchies to cover {} percent of cells activity!\".format(PERC_COVER * 100))\n",
    "\n",
    "try:\n",
    "      print('cluster level and percentage for > 90 perc total coverage is',\\\n",
    "            [(K,V) for K, V in synClust.activityCover['total'].items() if V > PERC_COVER][-1])\n",
    "except:\n",
    "      print(\"not enough hierarchies to cover {} percent of total activity!\".format(PERC_COVER * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the number of hierarchies used to find spatially significant clusters based on the % of activity covered. Eg, if 20 levels cover say 90% of the activity, choose this.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nHierarchies = 20\n",
    "synClust.rowData = synClust.rowData[-nHierarchies:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional - plot a few things as a sanity check:\n",
    "1) Mean heatmap of activity associated with a cluster at each level\n",
    "2) Create movies of just the \"hotspots\" corresponding to a cluster (pick how many hotspots to shorten!) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/Dropbox/Research/Science/Projects/Columbia/Code/Analysis/github/voltage/scripts/synFunc.py:481: RuntimeWarning: divide by zero encountered in divide\n",
      "  pixWt = np.nan_to_num(1/pixOverlaps,0,posinf=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x71bcffbd48b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.ioff()\n",
    "\n",
    "synClust.plotHmaps()                                    # Plot mean heatmap associated with clusters for EVERY level of hierachy                                         \n",
    "\n",
    "HIERARCHY = 5       # Cluster hierarchy to create exemplar videos of activity\n",
    "N_BLOBS = 10        # Number of activity episodes to display for each cluster\n",
    "SPEED = 0.5         # Speed of movie\n",
    "#synClust.getClustMovies(HIERARCHY, Speed = 0.5, Short = N_BLOBS)     # Create video\n",
    "\n",
    "plt.close('all')\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) Search through cluster hierarchy & find spatially separated clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm to search through cluster hierarchy and identify significantly separated spatial clusters. Save cluster labels and plot the mean heatmap of each significant cluster. The algorithm works as follows:\n",
    "\n",
    "1) Start by selecting the largest, most strongly clustered cluster. \n",
    "2) Search \"down\" by splitting the cluster into child clusters until the children are not significant. Save all significant clusters and discard any further child clusters down the hierarchy.\n",
    "3) Move onto the next largest spatially separate cluster. First test if it is separate from existing clusters. \n",
    "    * Yes: repeat step 1\n",
    "    * No: discard, return to step 2\n",
    "4) Repeat until all clusters are accounted for, down to a specified hierarchy depth.  \n",
    "\n",
    "How to determine whether to split a parent cluster into 2 child clusters:\n",
    "1) Compute the silhouette score of the child clusters\n",
    "2) Generate N surrogate Gaussian datasets of the parent\n",
    "3) Cluster N surrogate datasets into 2 separate clusters (K-means) and get N surrogate silhouette scores\n",
    "4) Check if the child silhouette score is > than the Xth percentile of the parent-based surrogates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "getting significance for parent  306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-07 20:32:21,785\tINFO worker.py:2012 -- Started a local Ray instance.\n",
      "/home/alex/miniconda3/envs/voltage_3/lib/python3.9/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0\n",
      "  warnings.warn(\n",
      "\u001b[36m(pid=12139)\u001b[0m <frozen importlib._bootstrap_external>:1181: FutureWarning: The cuda.cudart module is deprecated and will be removed in a future release, please switch to use the cuda.bindings.runtime module instead.\n",
      "\u001b[36m(pid=12139)\u001b[0m <frozen importlib._bootstrap_external>:1181: FutureWarning: The cuda.cuda module is deprecated and will be removed in a future release, please switch to use the cuda.bindings.driver module instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "percentile for parent 306 and children 305 & 300 is 0.0\n",
      "populating\n",
      "\n",
      "moving onto cluster 307. Remaining labels are\n",
      " [307, 316, 299, 291, 312, 289, 251, 303, 286, 275, 259, 270, 308, 235, 252, 277, 261, 267, 276, 294]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/Dropbox/Research/Science/Projects/Columbia/Code/Analysis/github/voltage/scripts/synFunc.py:1415: RuntimeWarning: invalid value encountered in divide\n",
      "  points = [getDots(np.nan_to_num(HM/HM), Scale=1) for HM in [hm1, hm2]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters [235, 259, 277, 291, 299, 306, 316] are separate. Adjacent cluster sig between 307 & 252 is 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(pid=gcs_server)\u001b[0m [2025-11-07 20:32:51,105 E 11808 11808] (gcs_server) gcs_server.cc:302: Failed to establish connection to the event+metrics exporter agent. Events and metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
      "\u001b[36m(pid=12160)\u001b[0m <frozen importlib._bootstrap_external>:1181: FutureWarning: The cuda.cudart module is deprecated and will be removed in a future release, please switch to use the cuda.bindings.runtime module instead.\u001b[32m [repeated 47x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(pid=12160)\u001b[0m <frozen importlib._bootstrap_external>:1181: FutureWarning: The cuda.cuda module is deprecated and will be removed in a future release, please switch to use the cuda.bindings.driver module instead.\u001b[32m [repeated 47x across cluster]\u001b[0m\n",
      "\u001b[33m(raylet)\u001b[0m [2025-11-07 20:32:51,718 E 11988 11988] (raylet) main.cc:975: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
      "\u001b[36m(KmFit pid=12088)\u001b[0m [2025-11-07 20:32:52,144 E 12088 12406] core_worker_process.cc:825: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
      "[2025-11-07 20:32:52,352 E 11620 12087] core_worker_process.cc:825: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters [235, 259, 277, 291, 299, 306, 316] are separate. Adjacent cluster sig between 307 & 275 is 100.0\n",
      "Clusters [235, 259, 277, 291, 299, 306, 316, 275] are separate. Adjacent cluster sig between 307 & 286 is 100.0\n",
      "Clusters [235, 259, 277, 291, 299, 306, 316, 275, 286] are separate. Adjacent cluster sig between 307 & 289 is 100.0\n",
      "Clusters [235, 259, 277, 291, 299, 306, 316, 275, 286, 289] are separate. Adjacent cluster sig between 307 & 312 is 100.0\n",
      "\n",
      "not testing children of cluster 307\n",
      "\n",
      "moving onto cluster 316. Remaining labels are\n",
      " [316, 299, 291, 312, 289, 251, 303, 286, 275, 259, 270, 308, 235, 277, 261, 267]\n",
      "\n",
      "Clusters [235, 252, 259, 275, 277, 286, 289, 291, 307] are separate. Adjacent cluster sig between 316 & 299 is 100.0\n",
      "Clusters [235, 252, 259, 275, 277, 286, 289, 291, 307, 299] are separate. Adjacent cluster sig between 316 & 306 is 100.0\n",
      "Clusters [235, 252, 259, 275, 277, 286, 289, 291, 307, 299, 306] are separate. Adjacent cluster sig between 316 & 312 is 100.0\n",
      "\n",
      "testing children of cluster 316\n",
      "\n",
      "getting significance for parent  316\n",
      "\n",
      "percentile for parent 316 and children 303 & 251 is 0.0\n",
      "populating\n",
      "\n",
      "moving onto cluster 299. Remaining labels are\n",
      " [299, 291, 312, 289, 286, 275, 259, 270, 308, 235, 277, 261, 267]\n",
      "\n",
      "Clusters [235, 252, 259, 275, 277, 289, 291, 307, 312] are separate. Adjacent cluster sig between 299 & 286 is 100.0\n",
      "Clusters [235, 252, 259, 275, 277, 289, 291, 307, 312, 286] are separate. Adjacent cluster sig between 299 & 306 is 100.0\n",
      "Clusters [235, 252, 259, 275, 277, 289, 291, 307, 312, 286, 306] are separate. Adjacent cluster sig between 299 & 316 is 100.0\n",
      "\n",
      "testing children of cluster 299\n",
      "\n",
      "moving onto cluster 291. Remaining labels are\n",
      " [291, 312, 289, 286, 275, 259, 270, 308, 235, 277, 261, 267]\n",
      "\n",
      "\n",
      "testing children of cluster 291\n",
      "\n",
      "moving onto cluster 312. Remaining labels are\n",
      " [312, 289, 286, 275, 259, 270, 308, 235, 277, 261, 267]\n",
      "\n",
      "Clusters [235, 252, 259, 277, 286, 291, 299] are separate. Adjacent cluster sig between 312 & 275 is 100.0\n",
      "Clusters [235, 252, 259, 277, 286, 291, 299, 275] are separate. Adjacent cluster sig between 312 & 289 is 100.0\n",
      "Clusters [235, 252, 259, 277, 286, 291, 299, 275, 289] are separate. Adjacent cluster sig between 312 & 306 is 100.0\n",
      "Clusters [235, 252, 259, 277, 286, 291, 299, 275, 289, 306] are separate. Adjacent cluster sig between 312 & 307 is 100.0\n",
      "Clusters [235, 252, 259, 277, 286, 291, 299, 275, 289, 306, 307] are separate. Adjacent cluster sig between 312 & 316 is 100.0\n",
      "\n",
      "testing children of cluster 312\n",
      "\n",
      "getting significance for parent  312\n",
      "\n",
      "percentile for parent 312 and children 308 & 270 is 0.0\n",
      "populating\n",
      "\n",
      "moving onto cluster 289. Remaining labels are\n",
      " [289, 286, 275, 259, 235, 277]\n",
      "\n",
      "Clusters [235, 259, 277, 286, 291, 299, 306, 316] are separate. Adjacent cluster sig between 289 & 252 is 100.0\n",
      "Clusters [235, 259, 277, 286, 291, 299, 306, 316, 252] are separate. Adjacent cluster sig between 289 & 275 is 100.0\n",
      "Clusters [235, 259, 277, 286, 291, 299, 306, 316, 252, 275] are separate. Adjacent cluster sig between 289 & 307 is 100.0\n",
      "Clusters [235, 259, 277, 286, 291, 299, 306, 316, 252, 275, 307] are separate. Adjacent cluster sig between 289 & 312 is 100.0\n",
      "\n",
      "testing children of cluster 289\n",
      "\n",
      "moving onto cluster 286. Remaining labels are\n",
      " [286, 275, 259, 235, 277]\n",
      "\n",
      "Clusters [235, 259, 277, 289, 291, 306, 312, 316] are separate. Adjacent cluster sig between 286 & 252 is 100.0\n",
      "Clusters [235, 259, 277, 289, 291, 306, 312, 316, 252] are separate. Adjacent cluster sig between 286 & 275 is 100.0\n",
      "Clusters [235, 259, 277, 289, 291, 306, 312, 316, 252, 275] are separate. Adjacent cluster sig between 286 & 299 is 100.0\n",
      "Clusters [235, 259, 277, 289, 291, 306, 312, 316, 252, 275, 299] are separate. Adjacent cluster sig between 286 & 307 is 100.0\n",
      "\n",
      "testing children of cluster 286\n",
      "\n",
      "moving onto cluster 275. Remaining labels are\n",
      " [275, 259, 235, 277]\n",
      "\n",
      "Clusters [235, 259, 277, 291, 299, 306, 316] are separate. Adjacent cluster sig between 275 & 252 is 100.0\n",
      "Clusters [235, 259, 277, 291, 299, 306, 316, 252] are separate. Adjacent cluster sig between 275 & 286 is 100.0\n",
      "Clusters [235, 259, 277, 291, 299, 306, 316, 252, 286] are separate. Adjacent cluster sig between 275 & 289 is 100.0\n",
      "Clusters [235, 259, 277, 291, 299, 306, 316, 252, 286, 289] are separate. Adjacent cluster sig between 275 & 307 is 100.0\n",
      "Clusters [235, 259, 277, 291, 299, 306, 316, 252, 286, 289, 307] are separate. Adjacent cluster sig between 275 & 312 is 100.0\n",
      "\n",
      "testing children of cluster 275\n",
      "\n",
      "moving onto cluster 259. Remaining labels are\n",
      " [259, 235, 277]\n",
      "\n",
      "\n",
      "testing children of cluster 259\n",
      "\n",
      "moving onto cluster 235. Remaining labels are\n",
      " [235, 277]\n",
      "\n",
      "\n",
      "testing children of cluster 235\n",
      "\n",
      "moving onto cluster 277. Remaining labels are\n",
      " [277]\n",
      "\n",
      "\n",
      "testing children of cluster 277\n",
      "\n",
      " Detected significant clusters are: [306, 316, 299, 291, 312, 289, 286, 275, 259, 235, 277]\n",
      "\n",
      " Now plotting mean heatmaps of significant clusters\n"
     ]
    }
   ],
   "source": [
    "NORM = True                    # Whether to normalise Gaussians when comparing 2 clusters\n",
    "THRESH = 95                     # Significant threshold for distinct clusters based on random \n",
    "LABELS = True                   # Whether to plot the cluster label number next to each heatmap\n",
    "\n",
    "synClust.getClusterSignificance(NORM, THRESH, LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sF.plotMeanEnsHm(synClust.actM, synClust.rowData, labelText=True, Dim = synClust.spatialDims, \\\n",
    "#                 Save = 'norm' + str(NORM) + '_Labels_thresh' + str(THRESH) + '_', \\\n",
    "#                 clusterList = synClust.clLabels, clusterLabels = [int(tCl) for tCl in synClust.sigClusters],\\\n",
    "#                    UPSAMPLE = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Testing***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a cluster and all of it's child subclusters: either on the same plot or different plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER = 307                                                       # Cluster number to plot\n",
    "\n",
    "sF.plotSubClusters(CLUSTER, synClust.clTree, synClust.clLabels, synClust.actM, \\\n",
    "                   synClust.rowData, Dim = synClust.spatialDims)    # Cluster is saved in figures folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the significance of any 2 arbitrary clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TEST SIGNIFICANCE OF ANY 2 ARBITRARY CLUSTERS\n",
    "rel()\n",
    "sig, Dots, Hms, gData, si, scores = sF.clusterSigTest((254,305), synClust.rowData, \\\n",
    "                                    synClust.actM, Dim = synClust.spatialDims, nDots = 1000, norm = True)\n",
    "\n",
    "print(\"Separation significance is {}. Silhouette score for original clusters is {}. Mean/std of \\n \\\n",
    "silhouette scores for clusters approximated by single Gaussian is {}/{}\".format(sig, si, \\\n",
    "    np.round(np.mean(scores), 3), np.round(np.std(scores), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT TEST DATA\n",
    "ALPH = 0.25\n",
    "(Y, X) = synClust.spatialDims\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (3, 3 * (Y / X)))\n",
    "\n",
    "ax.scatter(np.array(Dots[0]).T[1],np.array(Dots[0]).T[0], alpha = ALPH, color = 'black')\n",
    "ax.scatter(np.array(Dots[1]).T[1],np.array(Dots[1]).T[0], alpha = ALPH, color = 'blue')\n",
    "\n",
    "#ax.scatter(np.array(Dots[2]).T[1],np.array(Dots[2]).T[0],alpha=0.1)\n",
    "#ax.scatter(gData[0].T[1], gData[0].T[0], alpha = 0.1, color = 'green')\n",
    "\n",
    "ax.set_ylim([synClust.spatialDims[0],0]), ax.set_xlim([0,synClust.spatialDims[1]])\n",
    "\n",
    "ax.legend(['Cluster 1','Cluster 2','Estimated gaussian'], fontsize = 8)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voltage_3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
